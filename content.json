{"pages":[],"posts":[{"title":"Brief introduction of database and storage engine","text":"123456789101112131415161718192021222324252627281. 数据库：物理操作系统文件或其他形式文件类型的集合。2. (数据库)实例：MySQL数据库是由后台线程以及一个共享内存区组成。共享内存可以被运行的后台线程所共享。3. 数据库实例才是真正用于操作数据库文件的。4. MySQL被设计成一个单进程多线程架构的数据库，这点与SQL Server比较类似。5. mysql –help | grep my.cnf查看读取配置文件的顺序。MySQL数据库会以读取到的最后一个配置文件为准。6. MySQL的组成部分：连接池组件、管理服务和工具组件、SQL接口组件、查询分析器组件、优化器组件、缓冲(Cache)组件、插件式存储引擎、物理文件。7. MySQL区别于其他数据库最重要的一个特点就是插件式的表存储引擎。存储引擎是基于表的。8. MySQL的黑心核心在于存储引擎。9. 存储引擎的介绍：Innodb引擎：支持事务，其设计目标主要是面向在线事务处理(OLTP)的应用，其特点是行锁设计、支持外键、支持类似Oracle的非锁定读(即默认的读取操作不会产生锁)，innodb存储引擎将数据放在一个逻辑的表空间中，充MySQL4.1开始，它可以将每个innodb存储引擎的表单独存放在一个独立的ibd文件中。Innodb支持用row risk用来建立其表空间。Innodb通过使用多版本并发控制（MVCC）来获得高并发性。对于表中数据的存储，innodb存储引擎采用的是聚集的方式，每张表的存储都是按主键的顺序进行存放。Innodb具备高可用性、高性能、以及高可扩展性。MyISAM存储引擎：不支持事务、表锁设计，支持全文索引，主要面向一些OLAP数据库应用。它的缓冲池只缓存索引文件，而不缓冲数据文件。从MySQL5.0开始MyISAM支持256TB的单表数据，64位的系统支持大于4G的索引缓冲区。NDB存储引擎：集群存储引擎， NDB的特点是数据全部放在内存中（5.1后，可以将非索引数据放在磁盘上），因此主键查找的速度极快，通过添加NDB数据存储节点可以线性的提高数据库性能，是高可用、高性能的集群系统。它的连接操作（join）是在MySQL数据库底层完成的，而不是在存储引擎层完成的，复杂的连接操作需要巨大的网络开销，因此查询速度很慢。Memory存储引擎：将表中的数据存在内存中，如果数据库重启或发生崩溃，表中的数据都将消失。它非常适合用于存储临时数据的临时表，默认使用哈希索引。虽然Memory存储引擎速度非常快，但是只支持表锁，并发性能差，不支持text和blob列类型，更重要的是存储varchar是按照char的方式进行的，已经解决。","link":"/2021/02/10/1.Brief-introduction-of-database-and-storage-engine/"},{"title":"Brief introduction of InnoDB engine","text":"123456789101112131415161718192021222324252627282930313233341. Innodb的体系结构：innodb存储引擎有多个内存块，组成一个大的内存池，负责以下工作。(1)维护所有进程/线程需要访问的多个内部数据结构。(2)缓存磁盘上的数据，方便快速读取，同时在对磁盘文件的数据修改之前在这里缓存。(3)重做日志(redo log)缓冲…2. 后台线程 主要作用是负责刷新内存池中的数据，保证缓冲池中的内存缓存的是最近的数据。3. 四个重要的后台线程:(1)Master Thread是一个非常核心的后台线程，主要负责将缓冲池中的数据异步刷新到磁盘，保证数据的一致性，包括脏页的刷新、合并插入缓冲、undo页的回收等。(2)IO Thread，在innodb存储引擎中大量使用了AIO(Async IO)来处理写IO请求，这样可以极大提高数据库的性能，IO Thread主要负责这些IO请求的回调(call back)处理。(3)Purge Thread，事务被提交后，其所使用的undo log可能不在需要，因此需要Purge Thread来回收已经使用并分配的undo页。(4)Page Cleaner Thread其作用是将之前版本中的脏页的刷新操作都放到单独的线程中来完成，目的是为了减轻原Master Thread的工作及对于用户查询线程的阻塞，进一步提高了innodb的性能。4. 缓冲池innodb是基于磁盘存储的，并将其中的记录按照页的方式进行管理，因此可以将其视为基于磁盘的数据库系统。它通常使用缓冲池技术来提高数据库的整体性能。缓冲池简单来说就是一块内存区域，通过内存的速度来弥补磁盘速度较慢对数据库性能的影响。缓冲池中的数据页累心有：索引页、数据页、undo页、插入缓冲、自适应哈希索引、innodb存储的锁信息、数据字典信息等，前两者占了很大的比重。可以通过参数innodb_buffer_pool_size来设置。允许有多个缓冲池实例，可以通过innodb_buffer_pool_instance来设置。information_schema.innodb_buffer_pool_stats来查看状态。5. 读取页的操作首先将从磁盘读取到的页存放到缓冲池中，这个过程称为将页FIX在缓冲池中，下一次再读相同的页时，首先会判断该页是否在缓冲池中在数据库中修改页的操作，首先修改缓冲池中的页，然后再以一定的频率刷新到磁盘上需要注意的是，页充缓冲池刷新回磁盘的操作并不是在每次页发生更新时触发而是通过一种称为checkpoint的机制刷新回磁盘。6. LRU List、Free List和Flush List：(1)LRU,数据库中的缓冲池是通过LRU(Latest Recent Used)算法来进行管理的。 即最频繁使用的页在LRU列表的最前端，而最少使用的页在LRU的尾端，优先释放LRU列表中尾端的页。 缓冲池页的大小默认是16k，Innodb存储引擎对LRU算法进行了一些优化最新访问的页是放在LRU的midpoint，默认是5/8位置处。midpoint之前的位置是最为活跃的热点数据。 innodb引擎支持压缩页的功能，由于页的大小发生了改变，LRU列表也有了些许的改变(2)Free List，当数据库刚启动时，LRU列表中的数据是空的，这时页都放在Free列表中。(3)Flush List缓冲池中的页和磁盘中的页不一致时，数据库会通过checkpoint机制将脏页数据刷新回磁盘，而flush列表中的页即为脏页列表 需要注意的是，脏页即存在于LRU列表中，也存在于FLush List中，LRU列表用来管理缓冲池中页的可用性，Flush列表用来管理将页刷新回磁盘，两者互不影响。7. 脏页缓冲池中的页和磁盘上的页的数据产生了不一致。可以通过show engine innodb status中的modified db page来查看脏页的数量。8. 重做日志缓冲innodb引擎首先将重做日志信息放到这个缓冲区，然后按一定的频率将其刷新到重做日志文件，重做日志缓冲一般不需要设置得很大，因为一般情况下每一秒钟会将重做日志缓冲刷新到日志文件","link":"/2021/02/10/2.Brief-introduction-of-InnoDB-engine/"},{"title":"Files","text":"1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495961参数文件动态参数(global):该参数修改的是基于整个实例的生命周期set global key=value;set @@global.key=value;静态参数(session):该参数修改的是基于当前会话set session key=value;set @@session.key=value;2日志文件mysql中,主要存在5种日志：错误日志(error log)：记录mysql服务的启停时正确和错误的信息，还记录启动、停止、运行过程中的错误信息查询日志(general log)：记录建立的客户端连接和执行的语句,可以通过开启general log来记录某些执行过程(mysqldump备份的过程,主从一致性校验等)二进制日志(bin log)：记录所有更改数据的语句，可用于数据复制#拓展二进制文件的三种日志格式：statement row mixedstatement优：写入日志文件的数据更少,意味着可以更快的完成备份和还原操作;日志文件包含了所有进行了任何更改的语句,因此它们可用于审核数据库。 缺：存在不确定的行为,可能导致主从不一致的问题row优：可以复制所有更改,这是最安全的复制形式; 缺：日志量大,影响主从复制的时间(full),虽然说可以通过设置binlog_row_image=minimal来减少日志的生成量,但不建议 数据被误更改，无法用mysqlbinlog等工具闪回,容易造成数据不一致的问题mixed优：混合模式是STATEMENT和ROW格式的混合使用，判断使用哪种格式由数据库决定show {binary,master} logs;查看使用了哪些日志文件show binlog event in 'log_name' from pos;查看某个binlog某个位置的情况show master status;显示朱服务器的二进制信息分析binlog:mysqlbinlog -v --base64-output=decode-rows --start-position=1467(Exec_Master_Log_Pos) --stop-position=2125(Last_SQL_Error中的End_Master_Log_Pos) mysql-bin.000012(Relay_Master_Log_File) &gt; xxx.sql慢查询日志(slow log)：记录所有执行时间超过long_query_time的所有查询或不使用索引的查询可以通过mysqldumpslow工具查看日志详情-d debug -v verbose：显示详细信息-t NUM just show the top n queries：仅显示前n条查询-a don't abstract all numbers to N and strings to 'S'：归类时不要使用N替换数字,S替换字符串-g PATTERN grep: only consider stmts that include this string：通过grep来筛选select语句中继日志(relay log)：主从复制时使用的日志,从库sql_thread会读取中继日志,并顺序执行该日志的sql事件,从而与主库的数据包保持一致事务日志：redo日志undo日志:提供回滚和多版本并发控制https://www.junmajinlong.com/mysql/index/3套接字文件(socket文件)show variables like 'socket';4pid文件当mysql实例启动时，会将自己的进程ID写入到一个文件中,改文件即为pid文件5表结构定义文件因为MySQL是插件式存储引擎的体系结构,MySQL数据的存储是根据表进行的,每个表都会有与之对应的文件,但不论表采用了何种存储引擎MySQL都会有一个后缀名为frm的文件,这个文件记录了该表的表结构定义其中视图的frm可以通过cat查看6innodb存储引擎文件6.1表空间文件：innodb采用将存储的数据按表空间(table space)进行存放的设计,在默认配置下会有一个初始大小为10M,名为ibdata1的文件 改文件就是默认的表空间文件,用户可以通过参数innodb_data_file_path对其进行设置,设置这个参数后,所有基于innodb存储 引擎的表的数据都会记录到该共享表空间中;若设置了参数innodb_file_per_table则用户可以将每个基于innodb引擎的表产生 一个独立的表空间文件(.ibd),需要注意的是这些单独的表空间仅存储该表的数据、索引和插入缓冲BITMAP等信息,其余信息还是 存放在默认的表空间中6.2重做日志文件在默认的情况下,在innodb存储引擎的数据目录下有两个名为ib_logfile0和ib_logfile1;重做日志对innodb存储引擎至关重要,他们记录的是innodb存储引擎的事务日志.当实例或介质失败时,重做日志文件就能派上用场。例如：数据库由于所在主机掉电导致实例失败,innodb存储引擎会使用重做日志恢复到掉电前的时刻,以此来保证数据库的完整性。每个innodb存储引擎至少有一个重做日志组,每个文件组下至少有2个重做日志文件,如默认的ib_logfile0和ib_logfile1为了得到更高的可靠性,用户可以设置多个的镜像日志组,将不同的文件组放到不同的磁盘上,以此提高重做日志的高可用性。在日志组中每个重做日志文件的大小一致,并以循环写入的方式运行。下列参数影响着重做日志文件的属性：innodb_log_file_sizeinnodb_log_files_in_groupinnodb_mirrored_log_groups(5.7之后已删除)innodb_log_group_home_dir同样是记录事务日志,重做日志和二进制日志的区别：(1)二进制日志会记录所有与MySQL数据库有关的日志记录,包括innodb、myisam、Heap等其他引擎的日志 而innodb存储引擎的重做日志至记录有关该引擎本身的事务日志(2)记录的内容不同。无论用户将二进制日志文件记录格式设为statement还是row,又或者是mixed,其记录的都是一个事务的具体操作内容,即该日志是逻辑日志。 innodb存储引擎的重做日志记录的是关于每个页的更改的物理情况。(3)写入的时间也不同,二进制日志文件仅在事务提交前进行提交,即只写磁盘一次,不论该事务有多大; 在事务的进行过程中,却不断有重做日志条目被写入到重做日志文件中写入重做日志文件的操作不是直接写,而是先写入一个重做日志缓冲中,然后按一定的条件顺序写入到日志文件中redo log buffer-&gt;redo log files(ib_logfile0,ib_logfile1...)在重做日志缓冲(redo log block)往磁盘写入时,是按512个字节,也就是按一个扇区的大小进行写入,其中innodb的页大小是16k。因为扇区是写入的最小单位,因此可以保证写入必定是成功的因此重做日志的写入过程不需要有doublewrite","link":"/2021/02/10/4.Files/"},{"title":"Key features of InnoDB engine","text":"1234567891011121314151617181920212223242526272829303132333435363738394041424344454647Innodb的关键特性包括：插入缓冲、两次写、自适应哈希索引、异步IO、刷新邻接页。1. 插入缓冲insert buffer和数据页一样，也是物理页的一个组成部分。Innodb存储引擎开创性的设计了insert buffer，对于非聚集索引的插入或更新操作，不是每一次的直接插入到索引页中，而是先判断插入的非聚集索引页是否在缓冲池中，若在，则直接插入；若不在，则先存放到一个insert buffer对象中一定的频率和情况进行insert buffer和辅助索引页子节点的merge（合并）操作，这时通常能将多个插入合并到一个操作中它的数据结构是一棵B+树Insert buffer的使用需要同时满足两个条件：索引是辅助索引；索引不是唯一的也就是说insert buffer的使用场景是非唯一辅助索引的插入操作可以通过show engine innodb status来查看，其中insert表示insert buffer，delete mark表示delete buffer，delete表示purge buffer。要考虑的一种请款是：当数据库出现宕机的情况，这时势必有大量的insert buffer并没有合并到实际的非聚集索引中去，恢复起来消耗很长的时间。目前insert buffer存在的一个问题是：在写密集的情况下，插入缓冲会占用过多的缓冲池内存，默认会占到1/2的缓冲池内存，可以修改ibuf_pool_size_per_max_size 为n，则最大只能使用1/n的缓冲池内存。change buffer,从Innodb1.0.x开始开始引入了change buffer，可视为insert buffer的升级版，innodb存储引擎可以对DML操作（insert、delete、update）都进行缓冲它们分别是insert buffer，delete buffer，purge buffer。使用对象依然是非唯一的辅助索引。从innodb1.2.x开始，可以通过innodb_change_buffer_max_size来控制change buffer最大的使用内存数量。insert buffer的使用场景是非唯一辅助索引的插入操作，insert buffer的数据结构是一棵B+树，负责对所有的表的辅助索引进行insert buffer，而这棵B+树存放在共享表空间中，默认也就是ibdata1中因此试图通过独立表空间ibd文件恢复表中的数据时，往往会导致check table失败，这是因为表的辅助索引中的数据可能还在insert buffer中，也就是共享表空间中所以通过ibd文件恢复后，还需要进行repair table操作来重建表上的辅助索引。2. 两次写Insert buffer带给innodb存储引擎的是性能上的提升，那个doublewrite带给innodb存储引擎的是数据页的可靠性。当数据库发生宕机时，可能innodb存储引擎正在写入某个页到表中，而这个页只写了一部分，比如16k的页，只写了前4K，之后就发生宕机了，这种情况称为部分写失效，有人会想到可以通过重做日志进行恢复但是必须清楚的认识到，重做日志中记录的是对页的物理操作。如果这个页本身已经发生了损坏，再对其进行重做是没有意义的，这就是说在应用重做日志前，用户需要一个页的副本，在写入失效时，先通过页的副本来还原该页，再进行重做，这就是doublewrite。3. 自适应哈希索引（AHI）哈希是一种非常快的查找方法，在一般情况下这种查找的时间复杂度为O(1),B+树的查找次数，取决于B+树的高度在生产环境中，B+树的高度一般是3-4层，故需要3-4次的查询Innodb存储引擎会监控对表上各索引页的查询，如果观察到建立哈希索引可以带来速度提升，则会建立哈希索引，称之为自适应哈希索引（AHI）,AHI是通过缓冲池的B+树页构造而来，因此建立的速度很快Innodb存储引擎会自动根据访问的频率和模式来自动的为某些热点页建立哈希索引。可以通过innodb_adaptive_hash_index来考虑是否启用此特性，默认AHI是开启的4. 异步IO为了提高磁盘操作性能，当前数据库都是采用异步IO的方式来处理磁盘操作，Innodb存储引擎也是如此用户在发出一个IO请求后立即再发出另一个IO请求，当参数innodb_use_native_aio用来控制是否启用Native AIO，默认是开启的在innodb存储引擎中，read ahead方式的读取都是通过AIO完成，脏页的刷新，即磁盘的写入操作全部由AIO完成5. 刷新邻接页工作原理：当刷新一个脏页时，innodb存储引擎会检测该页所在区的所有页，如果是脏页，那么一起进行刷新这样做的好处是，通过AIO可以将多个IO写入操作合并为一个IO操作，顾该工作机制在传统机械磁盘下有着显著的优势Innodb1.2.x后提供了参数innodb_flush_neighbors来控制是否启用该特性传统机械磁盘建议开启","link":"/2021/02/10/3.Key-features-of-InnoDB-engine/"},{"title":"Replication","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657581异步复制、半同步复制、增强半同步复制 传统的异步复制存在数据丢失的情况,不建议使用,是基于binlog position的复制,要求slave有基准数据并且binlog的position位置一致 如果slave连接master时指定的binlog文件错误或者position(局部的)错误,会造成遗漏或者重复,很多时候数据是有依赖性的,这样就会出错导致数据不一致 MySQL默认的复制即是异步的,主库执行完客户端提交的事务后会立即将结果返回给客户端,并不关心从库是否已经接受并处理。这样就会存在一个问题,主如果crash掉了,此时主上已经提交的事务可能并没有传到从上,如果此时,强行将从提升为主,可能导致新主上的数据不完整,出现数据不一致的问题 半同步和增强半同步能确保已经提交的事务全部同步到至少一个从库中去,强数据完整性,并解决了幻读的问题 增强半同步:after_sync(默认)和after_commit2gtid(uuid+事务id) 全局事务ID,它不要求复制前slave有基准数据(master中的binlog完整),也不要求binlog的position一致 全局事务ID,所以slave在同步的时候不需要指定pos和binlog文件,MySQL会通过内部机制GTID自动找点同步 通过gtid保证每个主库上提交的事务在集群中有一个唯一的ID,这种方式强化了数据库的主备一致性,故障恢复及容错能力 优点:保证同一个事务在某slave上绝对只执行一次,没有执行过的gtid事务总是会被执行 不用像传统复制那样保证binlog的坐标准确,因为根本不需要binlog及坐标 故障转移到新的master的时候很方便,简化了很多任务 很容易判断master和slave的数据是都一致,只要master上提交的事务在slave也提交了,那么一定是一致的 gtid_excuted:表示已经执行过的gtid,reset master会清空该项的全局变量值3主从复制原理数据库有个bin-log二进制文件，记录了所有sql语句。我们的目标就是把主数据库的bin-log文件的sql语句复制过来。让其在从数据库的relay-log重做日志文件中再执行一次这些sql语句即可。具体需要三个线程来操作：(1)主库dump线程:每当有从库连接到主库的时候，主库都会创建一个dump线程然后发送binlog（二进制日志）内容到从库。在从库里，当复制开始的时候，从库就会创建两个线程进行处理：(2)从库IO线程:当START SLAVE语句在从库开始执行之后，从库创建一个IO线程，该线程连接到主库并请求主库发送binlog里面的更新记录到从库上。从库IO线程读取主库的binlog输出线程发送的更新并拷贝这些更新到 relay log 文件。(3)从库的SQL线程:从库创建一个SQL线程，这个线程读取从库IO线程写到 relay log 的更新事件并执行。从而实现主从的操作一致，最终数据一致；总之,slave是根据master的binlog二进制(记录了数据库的所有操作,是在server层完成的)日志完成复制的主从复制的用途：(1)做数据的热备；作为后备数据库，主数据库服务器故障后，可切换到从数据库继续工作，避免数据丢失。（实时灾备，用于故障切换）(2)读写分离，使数据库能支撑更大的并发；在报表中尤其重要。由于部分报表sql语句非常的慢，导致锁表，影响前台服务。如果前台使用master，报表使用slave，那么报表sql将不会造成前台锁，保证了前台速度半同步复制解决数据丢失的问题并行复制解决从库复制延迟的问题主从部署必要条件：(1)主库开启binlog日志(2)主从server-id不同(3)slave服务器能连通master4基于GTID的主从复制原理(1)master更新数据时,会在事务开始前产生GTID,一同记录到binlog中(2)每当有slave连接到master的时候,master都会创建一个dump线程然后发送binlog内容到slave(3)slave端的IO线程将变更的binlog,写入到本地的relay log中 (4)slave端的SQL线程从relay log中获取GTID,然后对比slave端的binlog是都有记录 如果有记录,说明该GTID事务已经执行,slave会忽略 如果没有记录,slave就会从relay log中执行该GTID的事务,并记录到binlog中 在读取执行事务前会先检查其他session持有该GTID，确保不被重复执行。(5)在解析过程中会判断是否有主键，如果有就用二级索引，如果没有就用全部扫描。5推荐使用的复制方案GTID+row+增强半同步 下面两种是增强半同步的两种模式,默认是after_sync","link":"/2021/03/02/Replication-1/"}],"tags":[{"name":"MySQL技术内幕","slug":"MySQL技术内幕","link":"/tags/MySQL%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95/"},{"name":"面试","slug":"面试","link":"/tags/%E9%9D%A2%E8%AF%95/"}],"categories":[]}